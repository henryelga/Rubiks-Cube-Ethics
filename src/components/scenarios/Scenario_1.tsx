const Scenario_1 = () => {
    return (
        <>
            <h1>⚖️ The Legal Void</h1>

            <section>
                <h2>Scenario 1: AI Develops a New Algorithm</h2>

                <p>
                    In this scenario, an Artificial Intelligence (AI) system independently
                    develops <strong>Algorithm X</strong>, a new and highly efficient method
                    for solving complex Rubik's Cube scrambles.
                </p>

                <p>
                    No human directly designed or discovered this method. The solution
                    emerged entirely from the AI's own internal processes.
                </p>

                <p>
                    This raises a simple but serious question:
                </p>
                <blockquote className="policy-quote">
                    Who is the inventor when no human actually invented the solution?
                </blockquote>
            </section>

            <section>
                <h2>Why This Creates a Legal Problem</h2>

                <p>
                    Current Intellectual Property (IP) laws are based on one main rule:
                    only <strong>human beings</strong> can be inventors.
                </p>

                <p>
                    When an AI produces a new solution on its own, the law has no
                    category to accurately describe what has occurred. This creates a
                    <strong> legal void</strong>, a situation where rules of the
                    past do not match the reality of the present.
                </p>
            </section>

            <section>
                <h2>Analysis: Conflicting Viewpoints</h2>

                <h3>The Legal Response</h3>
                <ul>
                    <li>
                        <strong>What the law requires:</strong> A patent must name a human
                        inventor.
                    </li>
                    <li>
                        <strong>What courts do:</strong> Courts usually give the credit to the
                        person who owns or programmed the AI.
                    </li>
                    <li>
                        <strong>The proof:</strong> In the DABUS cases, courts in the UK,
                        US, EU, and Australia all ruled that an AI system cannot be an
                        inventor under existing law.
                    </li>
                    <li>
                        <strong>The conflict: </strong>
                        This approach keeps the system moving, but it
                        relies on a <strong>legal fiction</strong>, crediting
                        invention to a human who did not actually invent.
                    </li>
                </ul>


                <h3>The Ethical Concern</h3>
                <ul>
                    <li>
                        <strong>The context: </strong>
                        AI systems are trained on vast amounts of shared human knowledge,
                        including open-source code, public research, and collective data.
                    </li>
                    <li>
                        <strong>The conflict: </strong>
                        Is it fair for one person to own a patent on something the AI learned from everyone?
                    </li>
                    <li>
                        <strong>The Risk: </strong>
                        Giving a person exclusive ownership over AI-generated ideas
                        might be ethically wrong because there was no "human spark" of creativity involved.
                    </li>
                </ul>
            </section>

            <section>
                <h2>The Breakdown</h2>

                <p>
                    The legal system is forced into a choice between two flawed options:
                </p>

                <ol>
                    <li>
                        <strong>Follow the old rules:</strong> Assign inventorship to a human
                        who did not invent, maintaining the system through fiction.
                    </li>
                    <li>
                        <strong>Acknowledge the truth:</strong> Recognize the AI's role,
                        which means the invention cannot be patented at all under current laws.
                    </li>
                </ol>

                <p>
                    Both outcomes expose the same issue: current laws are outdated, and lacks the tools
                    to deal directly with machine-created inventions.
                </p>
            </section>

            <section>
                <h2>Conclusion: What This Scenario Shows</h2>

                <p>
                    The problem is not that AI can invent, but that the law cannot
                    recognize non-human inventorship at all.
                </p>

                <p>
                    By forcing AI inventions into human categories, the
                    legal system conceals the problem rather than addressing it.
                </p>

                <p>
                    <strong>Scenario 1 </strong>demonstrates the absence of a legal
                    category for machine inventorship. This creates a legal void that current IP
                    law cannot resolve.
                </p>
            </section>

            <section>
                <h2>My Reflection</h2>

                <p>
                    Researching these cases shows that our laws are struggling to keep up with technology.
                    We are currently assuming humans are the inventors to make the old rules work.
                </p>

                <p>
                    Moving forward, I believe our challenge would be deciding where we should
                    intentionally keep humans in the loop to protect our sense of purpose.
                </p>
            </section>
        </>
    );
};

export default Scenario_1;
